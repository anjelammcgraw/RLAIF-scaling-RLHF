# ğŸ¤– RLAIF: Leveraging Constitutional AI to Scale RLHF

In this repo, we'll be creating a harmlessness dataset using our base model, constitutional AI, and self-refinement!. The base model we'll be using is the Zephyr-7b-alpha model. This project was done during Week 4 of AI Makerspace's LLM Engineering Cohort 2 (LLME2).

### âš™ï¸The colab links to the code are found below and will also be included in this repo. 

# âš™ï¸The Build Process

### Construct a harmlessness dataset using Constitutional AI, with RL and PPO.
The colab link is found [here.](https://colab.research.google.com/drive/15PTEP8mwupAC5NCBRMR5Ot21CmvSufJq?usp=sharing)

